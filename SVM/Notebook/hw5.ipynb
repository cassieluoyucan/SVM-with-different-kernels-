{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME: Yucan Luo usc_id : 8085970332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### read the data \n",
    "data = pd.read_csv('../Anuran Calls (MFCCs)/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
       "\n",
       "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
       "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### we found out that first 22 col is x feaures and 23,24,25 col are labels\n",
    "\n",
    "X = data.iloc[:, :22]\n",
    "y = data.iloc[:, 22:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### to split the data into train and test (70-30)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def split_data(X,y,label):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3,random_state=42)\n",
    "    y_train_label = y_train.loc[:, label]\n",
    "    y_test_label = y_test.loc[:, label]\n",
    "    \n",
    "    \n",
    "    ### standardize the features \n",
    "    std = StandardScaler()\n",
    "    X_train = pd.DataFrame(std.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(std.transform(X_test))\n",
    "    \n",
    "    return X_train, X_test, y_train_label, y_test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### split the data respect to its labels \n",
    "X_train, X_test, y_train_family, y_test_family = split_data(X,y,'Family')\n",
    "_, _, y_train_genus, y_test_genus = split_data(X,y,'Genus')\n",
    "_, _, y_train_species, y_test_species = split_data(X,y,'Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_train_family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-class classification is to train a classifier for each label. We first try this approach:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # i. Research exact match and hamming score/ loss methods for evaluating multi- label classification and use them in evaluating the classifiers in this problem.\n",
    "\n",
    "Exact matches: the predicted set of lablels should be exactly match with true set of lables.\n",
    "\n",
    "\n",
    "Hamming score: the fraction of the correct labels to the total number of lables.\n",
    "\n",
    "\n",
    "Hamming loss: the fraction of the wrong labels to the total number of labels. Hamming Loss =1- Hamming score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both standardized and raw attributes and report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def tunning_params(y_train_lable):\n",
    "    \n",
    "    ###set up space dictionary with specified hyperparameters\n",
    "    space = {'C'     : hp.loguniform('C', -3, 3),\n",
    "             'gamma' : hp.loguniform('gamma', -9, 0)}\n",
    "    \n",
    "    def f(params):\n",
    "        clf = SVC(**params) ### the default for kernel is already 'rbf' and default decision classifier is 'ovr'\n",
    "        best_score = cross_val_score(clf, X_train, y_train_lable, cv=10, \n",
    "                                     scoring='accuracy', n_jobs=-1).mean() # 10-fold cv\n",
    "        return 1- best_score\n",
    "\n",
    "\n",
    "    \n",
    "    trials = Trials()\n",
    "    # Run the algorithm\n",
    "    best = fmin(fn=f,\n",
    "                space=space, \n",
    "                max_evals=100, # Control how many evaluations to take\n",
    "                algo=tpe.suggest,\n",
    "                trials = trials)\n",
    "    \n",
    "    return best \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:28<00:00,  2.08s/trial, best loss: 0.00675155416706108]\n"
     ]
    }
   ],
   "source": [
    "#### get the best_params for family after tunning\n",
    "\n",
    "best_param_family =tunning_params(y_train_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6.0802372629398835, 'gamma': 0.06473978469242313}\n"
     ]
    }
   ],
   "source": [
    "print(best_param_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for family \n",
    "svc_family = SVC(**best_param_family)  \n",
    "svc_family.fit(X_train, y_train_family)\n",
    "y_pred_family = svc_family.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label family is 0.006484483557202408\n",
      "the hamming_socre for lable family is 0.9935155164427976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "hamming_loss_family =hamming_loss(y_pred_family, y_test_family)\n",
    "hamming_score_family = 1- hamming_loss_family\n",
    "\n",
    "print(\"the hamming_loss for label family is {}\".format(hamming_loss_family))\n",
    "print(\"the hamming_socre for lable family is {}\".format(hamming_score_family))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:24<00:00,  2.65s/trial, best loss: 0.009134478841238192]\n"
     ]
    }
   ],
   "source": [
    "#### get the best_params for label genus after tuning \n",
    "best_param_genus = tunning_params(y_train_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 18.329707291797714, 'gamma': 0.04748189630991691}\n"
     ]
    }
   ],
   "source": [
    "print(best_param_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for genus label \n",
    "svc_genus = SVC(**best_param_genus)  \n",
    "svc_genus.fit(X_train, y_train_genus)\n",
    "y_pred_genus = svc_genus.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label genus is 0.009263547938860583\n",
      "the hamming_socre for lable genus is 0.9907364520611395\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_genus =hamming_loss(y_pred_genus, y_test_genus)\n",
    "hamming_score_genus = 1- hamming_loss_genus\n",
    "\n",
    "print(\"the hamming_loss for label genus is {}\".format(hamming_loss_genus))\n",
    "print(\"the hamming_socre for lable genus is {}\".format(hamming_score_genus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:01<00:00,  2.42s/trial, best loss: 0.009928918552178922]\n"
     ]
    }
   ],
   "source": [
    "#### get the best_params for label species after tuning \n",
    "best_param_species = tunning_params(y_train_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 15.196147963209235, 'gamma': 0.03174314506698205}\n"
     ]
    }
   ],
   "source": [
    "print(best_param_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for species label \n",
    "svc_species = SVC(**best_param_species)  \n",
    "svc_species.fit(X_train, y_train_species)\n",
    "y_pred_species = svc_species.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label species is 0.012505789717461788\n",
      "the hamming_socre for lable species is 0.9874942102825383\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_species =hamming_loss(y_pred_species, y_test_species)\n",
    "hamming_score_species = 1- hamming_loss_species\n",
    "\n",
    "print(\"the hamming_loss for label species is {}\".format(hamming_loss_species))\n",
    "print(\"the hamming_socre for lable species is {}\".format(hamming_score_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### multi-label evaluation ###\n",
    "y_test = np.column_stack((y_test_family, y_test_genus, y_test_species))\n",
    "y_pred = np.column_stack((y_pred_family, y_pred_genus, y_pred_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score_multi(y_test, y_pred):\n",
    "    return np.sum(np.all(np.equal(y_test, y_pred), axis=1)) / y_test.shape[0]\n",
    "\n",
    "def hamming_score_multi(y_test, y_pred):\n",
    "    return np.mean((np.sum((np.equal(y_test, y_pred)), axis=1) / y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy score for multi lable (exact match) is 0.9905820595954918\n",
      "the hamming loss for multi lable is 0.009417940404508163\n"
     ]
    }
   ],
   "source": [
    "exact = hamming_score_multi(y_test, y_pred)\n",
    "print(\"the accuracy score for multi lable (exact match) is {}\".format(exact))\n",
    "\n",
    "hamming_loss_multi = 1- hamming_score_multi(y_test,y_pred)\n",
    "print(\"the hamming loss for multi lable is {}\".format(hamming_loss_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Repeat 1(b)ii with L1-penalized SVM Remember to standardize the attributes. Determine the weight of the SVM penalty using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###L1-penalized Linear SVM, since we alread standardized the features we can use it directly ###\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "def l1_opt_linear(y_train_lable):\n",
    "    \n",
    "    ###set up space dictionary with specified hyperparameters\n",
    "    space = {'alpha'     : hp.loguniform('alpha', -6, 3),}\n",
    "    \n",
    "    def fc(params):\n",
    "        clf = SGDClassifier(**params,penalty='l1',early_stopping= True,n_jobs=-1) \n",
    "        best_score = cross_val_score(clf, X_train, y_train_lable, cv=10, \n",
    "                                     scoring='accuracy', n_jobs=-1).mean() # 10-fold cv\n",
    "        return 1- best_score\n",
    "\n",
    "    \n",
    "    trials = Trials()\n",
    "    # Run the algorithm\n",
    "    best = fmin(fn=fc,\n",
    "                space=space, \n",
    "                max_evals=100, # Control how many evaluations to take\n",
    "                algo=tpe.suggest,\n",
    "                trials = trials)\n",
    "    \n",
    "    return best \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:58<00:00,  1.70trial/s, best loss: 0.06592350657957025]\n"
     ]
    }
   ],
   "source": [
    "l1_best_param_family = l1_opt_linear(y_train_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 fold validation  {'alpha': 0.0025999825722382106}\n"
     ]
    }
   ],
   "source": [
    "print(\"after 10 fold validation \",l1_best_param_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for family \n",
    "l1_family = SGDClassifier(**l1_best_param_family,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "l1_family.fit(X_train, y_train_family)\n",
    "y_pred_family_l1 = l1_family.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label family with l1 penalty is 0.07179249652616952\n",
      "the hamming_socre for lable family with l1 penalty is 0.9282075034738305\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_family_l1 =hamming_loss(y_pred_family_l1, y_test_family)\n",
    "hamming_score_family_l1 = 1- hamming_loss_family_l1\n",
    "\n",
    "print(\"the hamming_loss for label family with l1 penalty is {}\".format(hamming_loss_family_l1))\n",
    "print(\"the hamming_socre for lable family with l1 penalty is {}\".format(hamming_score_family_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.07327384896967393]\n"
     ]
    }
   ],
   "source": [
    "l1_best_param_genus = l1_opt_linear(y_train_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 fold validation the choosen alpha is   {'alpha': 0.002523845688237745}\n"
     ]
    }
   ],
   "source": [
    "print(\"after 10 fold validation the choosen alpha is  \",l1_best_param_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for genus\n",
    "l1_genus = SGDClassifier(**l1_best_param_genus,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "l1_genus.fit(X_train, y_train_genus)\n",
    "y_pred_genus_l1 = l1_genus.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label genus with l1 penalty is 0.08383510884668828\n",
      "the hamming_socre for lable genus with l1 penalty is 0.9161648911533117\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_genus_l1 =hamming_loss(y_pred_genus_l1, y_test_genus)\n",
    "hamming_score_genus_l1 = 1- hamming_loss_genus_l1\n",
    "\n",
    "print(\"the hamming_loss for label genus with l1 penalty is {}\".format(hamming_loss_genus_l1))\n",
    "print(\"the hamming_socre for lable genus with l1 penalty is {}\".format(hamming_score_genus_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:36<00:00,  1.03trial/s, best loss: 0.054206901448452194]\n"
     ]
    }
   ],
   "source": [
    "l1_best_param_species = l1_opt_linear(y_train_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 fold validation the choosen alpha is   {'alpha': 0.002523845688237745}\n"
     ]
    }
   ],
   "source": [
    "print(\"after 10 fold validation the choosen alpha is  \",l1_best_param_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for species \n",
    "l1_species = SGDClassifier(**l1_best_param_species,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "l1_species.fit(X_train, y_train_species)\n",
    "y_pred_species_l1 = l1_species.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hamming_loss for label species with l1 penalty is 0.06947660954145438\n",
      "the hamming_socre for lable species with l1 penalty is 0.9305233904585456\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_species_l1 =hamming_loss(y_pred_species_l1, y_test_species)\n",
    "hamming_score_species_l1 = 1- hamming_loss_species_l1\n",
    "\n",
    "print(\"the hamming_loss for label species with l1 penalty is {}\".format(hamming_loss_species_l1))\n",
    "print(\"the hamming_socre for lable species with l1 penalty is {}\".format(hamming_score_species_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### multi-label evaluation ###\n",
    "y_test = np.column_stack((y_test_family, y_test_genus, y_test_species))\n",
    "y_pred_l1 = np.column_stack((y_pred_family_l1, y_pred_genus_l1, y_pred_species_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy score with l1 penalty for multi lable (exact match) is 0.9249652616952293\n",
      "the hamming loss with l1 penalty for multi lable is 0.0750347383047707\n"
     ]
    }
   ],
   "source": [
    "exact_l1 = hamming_score_multi(y_test, y_pred_l1)\n",
    "print(\"the accuracy score with l1 penalty for multi lable (exact match) is {}\".format(exact_l1))\n",
    "\n",
    "hamming_loss_multi_l1 = 1- hamming_score_multi(y_test,y_pred_l1)\n",
    "print(\"the hamming loss with l1 penalty for multi lable is {}\".format(hamming_loss_multi_l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so , for linear kernel with the l1 penalty, we can see that hamming loss increases a little(worse) compared to SVM with Guassian kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "###to apply smote on training set \n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_family_sm, y_train_family_sm = sm.fit_resample(X_train, y_train_family)\n",
    "X_train_genus_sm, y_train_genus_sm = sm.fit_resample(X_train, y_train_genus)\n",
    "X_train_species_sm, y_train_species_sm = sm.fit_resample(X_train, y_train_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sm_l1_opt_linear(X_train, y_train_lable):\n",
    "    \n",
    "    ###set up space dictionary with specified hyperparameters\n",
    "    space = {'alpha'     : hp.loguniform('alpha', -6, 3)}\n",
    "    \n",
    "    def fc(params):\n",
    "        clf = SGDClassifier(**params,penalty='l1',early_stopping= True,n_jobs=-1) \n",
    "        best_score = cross_val_score(clf, X_train, y_train_lable, cv=10, \n",
    "                                     scoring='accuracy', n_jobs=-1).mean() # 10-fold cv\n",
    "        return 1- best_score\n",
    "\n",
    "    \n",
    "    trials = Trials()\n",
    "    # Run the algorithm\n",
    "    best = fmin(fn=fc,\n",
    "                space=space, \n",
    "                max_evals=100, # Control how many evaluations to take\n",
    "                algo=tpe.suggest,\n",
    "                trials = trials)\n",
    "    \n",
    "    return best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:55<00:00,  1.16s/trial, best loss: 0.05515628410962703]\n"
     ]
    }
   ],
   "source": [
    "sm_best_param_family = sm_l1_opt_linear(X_train_family_sm, y_train_family_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after apply smote the alpha chosen  {'alpha': 0.0025063642692590665}\n"
     ]
    }
   ],
   "source": [
    "print(\"after apply smote the alpha chosen \", sm_best_param_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for family \n",
    "sm_family = SGDClassifier(**sm_best_param_family,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "sm_family.fit(X_train_family_sm, y_train_family_sm)\n",
    "y_pred_family_sm = sm_family.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after smote the hamming_loss for label family with l1 penalty is 0.09031959240389069\n",
      "after smote the hamming_socre for lable family with l1 penalty is 0.9096804075961094\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_family_sm =hamming_loss(y_pred_family_sm, y_test_family)\n",
    "hamming_score_family_sm = 1- hamming_loss_family_sm\n",
    "\n",
    "print(\"after smote the hamming_loss for label family with l1 penalty is {}\".format(hamming_loss_family_sm))\n",
    "print(\"after smote the hamming_socre for lable family with l1 penalty is {}\".format(hamming_score_family_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:27<00:00,  2.68s/trial, best loss: 0.06726433435934032]\n"
     ]
    }
   ],
   "source": [
    "sm_best_param_genus = sm_l1_opt_linear(X_train_genus_sm,y_train_genus_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after apply smote the alpha chosen  {'alpha': 0.0027878799916807905}\n"
     ]
    }
   ],
   "source": [
    "print(\"after apply smote the alpha chosen \", sm_best_param_genus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for genus \n",
    "sm_genus = SGDClassifier(**sm_best_param_genus,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "sm_genus.fit(X_train_genus_sm, y_train_genus_sm)\n",
    "y_pred_genus_sm = sm_genus.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after smote, the hamming_loss for label genus with l1 penalty is 0.1000463177396943\n",
      "after smote, the hamming_socre for lable genus with l1 penalty is 0.8999536822603057\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_genus_sm =hamming_loss(y_pred_genus_sm, y_test_genus)\n",
    "hamming_score_genus_sm = 1- hamming_loss_genus_sm\n",
    "\n",
    "print(\"after smote, the hamming_loss for label genus with l1 penalty is {}\".format(hamming_loss_genus_sm))\n",
    "print(\"after smote, the hamming_socre for lable genus with l1 penalty is {}\".format(hamming_score_genus_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [05:49<00:00,  3.49s/trial, best loss: 0.05827543931344503]\n"
     ]
    }
   ],
   "source": [
    "sm_best_param_species = sm_l1_opt_linear(X_train_species_sm,y_train_species_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after apply smote the alpha chosen  {'alpha': 0.002515687358386086}\n"
     ]
    }
   ],
   "source": [
    "print(\"after apply smote the alpha chosen \", sm_best_param_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model for species \n",
    "sm_species = SGDClassifier(**sm_best_param_species,penalty='l1',early_stopping= True,n_jobs=-1)  \n",
    "sm_species.fit(X_train_species_sm, y_train_species_sm)\n",
    "y_pred_species_sm = sm_species.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after smote, the hamming_loss for label speices with l1 penalty is 0.05604446503010653\n",
      "after smote, the hamming_socre for lable speices with l1 penalty is 0.9439555349698935\n"
     ]
    }
   ],
   "source": [
    "hamming_loss_species_sm =hamming_loss(y_pred_species_sm, y_test_species)\n",
    "hamming_score_species_sm = 1- hamming_loss_species_sm\n",
    "\n",
    "print(\"after smote, the hamming_loss for label speices with l1 penalty is {}\".format(hamming_loss_species_sm))\n",
    "print(\"after smote, the hamming_socre for lable speices with l1 penalty is {}\".format(hamming_score_species_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### multi-label evaluation ###\n",
    "y_test = np.column_stack((y_test_family, y_test_genus, y_test_species))\n",
    "y_pred_sm = np.column_stack((y_pred_family_sm, y_pred_genus_sm, y_pred_species_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after smote,the accuracy score with l1 penalty for multi lable (exact match) is 0.9178632082754361\n",
      "after smote the hamming loss with l1 penalty for multi lable is 0.0821367917245639\n"
     ]
    }
   ],
   "source": [
    "exact_sm = hamming_score_multi(y_test, y_pred_sm)\n",
    "print(\"after smote,the accuracy score with l1 penalty for multi lable (exact match) is {}\".format(exact_sm))\n",
    "\n",
    "hamming_loss_multi_sm = 1- hamming_score_multi(y_test,y_pred_sm)\n",
    "print(\"after smote the hamming loss with l1 penalty for multi lable is {}\".format(hamming_loss_multi_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can see that the hamming loss increase a little after applying smote to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split the data into train and test, as we are not performing supervised learning in this exercise). Choose k automatically based on one of the methods provided in the slides (CH or Gap Statistics or scree plots or Silhouettes) or any other method you know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### this time we don't split the dataset \n",
    "### we only care about x \n",
    "\n",
    "#data.head()\n",
    "\n",
    "X_data = data.iloc[:,:-4] ### get rid of y lables \n",
    "y_data = data.iloc[:,22:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import MiniBatchKMeans # for large size data less computational intensive \n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_means_silhouette(k, x):\n",
    "    cluster = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "    \n",
    "    cluster_label = cluster.fit_predict(x)\n",
    "    \n",
    "    score = silhouette_score(x, cluster_label, metric=\"euclidean\")\n",
    "    \n",
    "    \n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range = [*range(2,51)] ## k start at 2 otherwise there's no menaing \n",
    "### initial the k and silhouette score \n",
    "k_score = [0,0] \n",
    "for k in k_range:\n",
    "    \n",
    "    score = k_means_silhouette(k,X_data)\n",
    "    \n",
    "    if score > k_score[1]: ### find the max score and store it's k \n",
    "        k_score = [k,score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using silhouette score, the best k is : 7 and the sihouette score is 0.37426410258135157\n"
     ]
    }
   ],
   "source": [
    "print(\"using silhouette score, the best k is : {} and the sihouette score is {}\".format(k_score[0], k_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) In each cluster, determine which family is the majority by reading the true labels. Repeat for genus and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the minibatchkmeans using best k \n",
    "best_k = k_score[0]\n",
    "cluster = MiniBatchKMeans(n_clusters=best_k, random_state=42)\n",
    "cluster_label = cluster.fit_predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data[\"label\"] = cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for each cluster get the majority family \n",
    "\n",
    "frequent_family = y_data.groupby(\"label\")[\"Family\"].agg(pd.Series.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    Leptodactylidae\n",
       "1    Leptodactylidae\n",
       "2      Dendrobatidae\n",
       "3            Hylidae\n",
       "4            Hylidae\n",
       "5    Leptodactylidae\n",
       "6    Leptodactylidae\n",
       "Name: Family, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majority label in each cluster shown as above for Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for genus and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    Leptodactylus\n",
       "1        Adenomera\n",
       "2         Ameerega\n",
       "3        Hypsiboas\n",
       "4        Hypsiboas\n",
       "5        Adenomera\n",
       "6        Adenomera\n",
       "Name: Genus, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_genus = y_data.groupby(\"label\")['Genus'].agg(pd.Series.mode)\n",
    "frequent_genus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majority label in each cluster shown as above for Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0       LeptodactylusFuscus\n",
       "1    AdenomeraHylaedactylus\n",
       "2        Ameeregatrivittata\n",
       "3      HypsiboasCinerascens\n",
       "4         HypsiboasCordobae\n",
       "5            AdenomeraAndre\n",
       "6            AdenomeraAndre\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_species = y_data.groupby(\"label\")['Species'].agg(pd.Series.mode)\n",
    "frequent_species "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majority label in each cluster shown as above for Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) Now for each cluster you have a majority label triplet (family, genus, species). Calculate the average Hamming distance, Hamming score, and Hamming loss between the true labels and the labels assigned by clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### assign majority label triplet to that cluster for family , genus and species \n",
    "y_data['Pred_Family'] = y_data['label'].map(frequent_family)\n",
    "y_data['Pred_Genus'] = y_data['label'].map(frequent_genus)\n",
    "y_data['Pred_Species'] = y_data['label'].map(frequent_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>label</th>\n",
       "      <th>Pred_Family</th>\n",
       "      <th>Pred_Genus</th>\n",
       "      <th>Pred_Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>6</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>6</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>6</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>6</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>6</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Family      Genus         Species  label      Pred_Family  \\\n",
       "0  Leptodactylidae  Adenomera  AdenomeraAndre      6  Leptodactylidae   \n",
       "1  Leptodactylidae  Adenomera  AdenomeraAndre      6  Leptodactylidae   \n",
       "2  Leptodactylidae  Adenomera  AdenomeraAndre      6  Leptodactylidae   \n",
       "3  Leptodactylidae  Adenomera  AdenomeraAndre      6  Leptodactylidae   \n",
       "4  Leptodactylidae  Adenomera  AdenomeraAndre      6  Leptodactylidae   \n",
       "\n",
       "  Pred_Genus    Pred_Species  \n",
       "0  Adenomera  AdenomeraAndre  \n",
       "1  Adenomera  AdenomeraAndre  \n",
       "2  Adenomera  AdenomeraAndre  \n",
       "3  Adenomera  AdenomeraAndre  \n",
       "4  Adenomera  AdenomeraAndre  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### first three columns are actual labels\n",
    "actual_label = [x.iloc[:, :3].values for _, x in y_data.groupby('label')] \n",
    "### last three columns are assigned labels\n",
    "assign_label = [x.iloc[:, 4:].values for _, x in y_data.groupby('label')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ham_distance(x):\n",
    "    ### if actural label not equal to assigned label, then distance +=1\n",
    "    return np.mean(np.sum(np.not_equal(x[0], x[1]), axis=1))\n",
    "\n",
    "def get_ham_score(x):\n",
    "    ### if assigned label equal to actual label, ham_score = correnct label / total label\n",
    "    return np.mean((np.sum((np.equal(x[0], x[1])), axis=1) / x[0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### get the hamming distance , hamming score ###\n",
    "hamming_dist = np.mean(list(map(get_ham_distance, zip(actual_label, assign_label))))\n",
    "hamming_score = np.mean(list(map(get_ham_score, zip(actual_label, assign_label))))\n",
    "hamming_loss = 1- hamming_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average hamming distance is 0.7246666381417686\n",
      "the average hamming_socre is 0.7584444539527438\n",
      "the average hamming_loss is 0.24155554604725615\n"
     ]
    }
   ],
   "source": [
    "print(\"the average hamming distance is {}\".format(hamming_dist))\n",
    "print(\"the average hamming_socre is {}\".format(hamming_score))\n",
    "print(\"the average hamming_loss is {}\".format(hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Simulation: Perform the following procedures 50 times, and report the average and standard deviation of the 50 Hamming Distances that you calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_k(x):\n",
    "    \n",
    "    ### each time find k from range {1,2,3,...50}\n",
    "    k_range= [*range(2,51)]\n",
    "    k_score = [0,0]\n",
    "    for k in k_range:\n",
    "        ### without random state to make sure each time generate different result \n",
    "        cluster = MiniBatchKMeans(n_clusters=k) \n",
    "    \n",
    "        cluster_label = cluster.fit_predict(x)\n",
    "    \n",
    "        score = silhouette_score(x, cluster_label, metric=\"euclidean\")\n",
    "        \n",
    "        if score > k_score[1]:\n",
    "            k_score = [k,score]\n",
    "            \n",
    "    ##after find best k and it's score ###\n",
    "    \n",
    "    best_k = k_score[0]\n",
    "    \n",
    "    return best_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### refit the model and get hamming socre hamming loss and hamming distance \n",
    "def refit_model(x,y):\n",
    "    ### get the best k from k_range \n",
    "    best_k = get_k(x)\n",
    "    ### refit the minibatchkmeans using best k \n",
    "    cluster = MiniBatchKMeans(n_clusters=best_k)\n",
    "    cluster_label = cluster.fit_predict(x)\n",
    "    \n",
    "    y[\"label\"] = cluster_label\n",
    "    \n",
    "    frequent_family = y.groupby(\"label\")[\"Family\"].agg(pd.Series.mode)\n",
    "    frequent_genus = y.groupby(\"label\")['Genus'].agg(pd.Series.mode)\n",
    "    frequent_species = y.groupby(\"label\")['Species'].agg(pd.Series.mode)\n",
    "    ### assign majority label triplet to that cluster for family , genus and species \n",
    "    y['Pred_Family'] = y['label'].map(frequent_family)\n",
    "    y['Pred_Genus'] = y['label'].map(frequent_genus)\n",
    "    y['Pred_Species'] = y['label'].map(frequent_species)\n",
    "    ### first three columns are actual labels\n",
    "    actual_label = [x.iloc[:, :3].values for _, x in y.groupby('label')] \n",
    "    ### last three columns are assigned labels\n",
    "    assign_label = [x.iloc[:, 4:].values for _, x in y.groupby('label')]\n",
    "    \n",
    "    ### get the average hamming distance , average hamming score ###\n",
    "    ham_dist = np.mean(list(map(get_ham_distance, zip(actual_label, assign_label))))\n",
    "    ham_score = np.mean(list(map(get_ham_score, zip(actual_label, assign_label))))\n",
    "    ham_loss = 1- ham_score\n",
    "    \n",
    "    return [ham_dist,ham_score,ham_loss]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comlete 50%\n",
      "complet\n"
     ]
    }
   ],
   "source": [
    "####  Monte-Carlo Simulation 50 times ####\n",
    "ham_50 = []\n",
    "\n",
    "X_data = data.iloc[:,:-4] ### get rid of y lables \n",
    "y_data = data.iloc[:,22:25]\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    if i == 25:\n",
    "        print(\"comlete 50%\")\n",
    "        \n",
    "    if i == 49:\n",
    "        print(\"complet\")\n",
    "    all_scores= refit_model(X_data,y_data)\n",
    "    \n",
    "    ham_50.append(all_scores)\n",
    "    \n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_scores= np.array(ham_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(three_scores, columns =[\"Hamming_distance\",\"Hamming_score\",\"Hamming_Loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming_distance</th>\n",
       "      <th>Hamming_score</th>\n",
       "      <th>Hamming_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833471</td>\n",
       "      <td>0.722176</td>\n",
       "      <td>0.277824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623222</td>\n",
       "      <td>0.792259</td>\n",
       "      <td>0.207741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.151217</td>\n",
       "      <td>0.616261</td>\n",
       "      <td>0.383739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.680941</td>\n",
       "      <td>0.319059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.726193</td>\n",
       "      <td>0.273807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hamming_distance  Hamming_score  Hamming_Loss\n",
       "0          0.833471       0.722176      0.277824\n",
       "1          0.623222       0.792259      0.207741\n",
       "2          1.151217       0.616261      0.383739\n",
       "3          0.957177       0.680941      0.319059\n",
       "4          0.821420       0.726193      0.273807"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### get mean and std for each score \n",
    "\n",
    "df = df_scores.describe().T[[ 'mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming_distance</th>\n",
       "      <th>Hamming_score</th>\n",
       "      <th>Hamming_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.887934</td>\n",
       "      <td>0.704022</td>\n",
       "      <td>0.295978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.138806</td>\n",
       "      <td>0.046269</td>\n",
       "      <td>0.046269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hamming_distance  Hamming_score  Hamming_Loss\n",
       "mean          0.887934       0.704022      0.295978\n",
       "std           0.138806       0.046269      0.046269"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 50 times simulation, we got the mean and std for Hamming distance, Hamming_score and Hamming_loss as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. ISLR 10.7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) On the basis of this dissimilarity matrix, sketch the dendrogram that results from hierarchically clustering these four observa- tions using complete linkage. Be sure to indicate on the plot the height at which each fusion occurs, as well as the observations corresponding to each leaf in the dendrogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial import distance_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram ')\n",
    "        plt.xlabel('sample index')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG8CAYAAACWvXInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X= np.array([[0,0.3,0.4,0.7],[0.3,0,0.5,0.8],[0.4,0.5,0,0.45],[0.7,0.8,0.45,0]])\n",
    "dists = squareform(X)\n",
    "linkage_matrix = linkage(dists, \"complete\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "fancy_dendrogram(linkage_matrix, labels=[\"1\", \"2\", \"3\",\"4\"],\\\n",
    "           distance_sort=\"descending\", \\\n",
    "           show_leaf_counts=True,\\\n",
    "           )\n",
    "plt.title(\"complete_linkage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Repeat (a), this time using single linkage clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG8CAYAAACWvXInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAMRBgDQgQgDAOhAhAEAdPD/ATnuQYAsVXITAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X= np.array([[0,0.3,0.4,0.7],[0.3,0,0.5,0.8],[0.4,0.5,0,0.45],[0.7,0.8,0.45,0]])\n",
    "dists = squareform(X)\n",
    "linkage_matrix = linkage(dists, \"single\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "fancy_dendrogram(linkage_matrix, labels=[\"1\", \"2\", \"3\",\"4\"],\\\n",
    "           distance_sort=\"descending\", \\\n",
    "           show_leaf_counts=True,\\\n",
    "           )\n",
    "plt.title(\"single_linkage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Suppose that we cut the dendogram obtained in (a) such that two clusters result. Which observations are in each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG8CAYAAACWvXInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIDhjBJkqQGDGGSJEkN/P92JFaVgsi77wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X= np.array([[0,0.3,0.4,0.7],[0.3,0,0.5,0.8],[0.4,0.5,0,0.45],[0.7,0.8,0.45,0]])\n",
    "dists = squareform(X)\n",
    "linkage_matrix = linkage(dists, \"complete\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "fancy_dendrogram(linkage_matrix, labels=[\"1\", \"2\", \"3\",\"4\"],\\\n",
    "           distance_sort=\"descending\", \\\n",
    "           show_leaf_counts=True,\\\n",
    "           max_d = 0.5\n",
    "           )\n",
    "plt.title(\"complete_linkage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we cut the dendogram in (a), we will have two culsters, one cluster is  (1,2) and another is (3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Suppose that we cut the dendogram obtained in (b) such that two clusters result. Which observations are in each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG8CAYAAACWvXInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAciDACgg/8PI59p64n40XAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X= np.array([[0,0.3,0.4,0.7],[0.3,0,0.5,0.8],[0.4,0.5,0,0.45],[0.7,0.8,0.45,0]])\n",
    "dists = squareform(X)\n",
    "linkage_matrix = linkage(dists, \"single\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "fancy_dendrogram(linkage_matrix, labels=[\"1\", \"2\", \"3\",\"4\"],\\\n",
    "           distance_sort=\"descending\", \\\n",
    "           show_leaf_counts=True,\\\n",
    "           max_d = 0.43\n",
    "           )\n",
    "plt.title(\"single_linkage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we cut the dendogram in (b), we will have two culsters, one cluster is (1,2,3) and another is (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) It is mentioned in the chapter that at each fusion in the den- drogram, the position of the two clusters being fused can be swapped without changing the meaning of the dendrogram. Draw a dendrogram that is equivalent to the dendrogram in (a), for which two or more of the leaves are repositioned, but for which the meaning of the dendrogram is the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAG8CAYAAACWvXInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X= np.array([[0,0.3,0.4,0.7],[0.3,0,0.5,0.8],[0.4,0.5,0,0.45],[0.7,0.8,0.45,0]])\n",
    "dists = squareform(X)\n",
    "linkage_matrix = linkage(dists, \"complete\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "fancy_dendrogram(linkage_matrix, labels=[\"2\", \"1\", \"4\",\"3\"],\\\n",
    "           distance_sort=\"descending\", \\\n",
    "           show_leaf_counts=True,\\\n",
    "           )\n",
    "plt.title(\"complete_linkage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
